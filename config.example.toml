# The port number for the proxy service. The proxied OpenAI API endpoint will be: http://localhost:3700/v1/chat/completions
port = 3700

# A list of poe tokens. You can get them from the cookies on poe.com, they look like this: p-b=fdasac5a1dfa6%3D%3D
tokens = ["fdasac5a1dfa6%3D%3D"]

# The proxy that will be used to connect to poe.com. Leave it blank if you do not use a proxy
proxy = ""

# The gateway url for the Python backend of poe-api.
# Note that if you use docker this value should be changed into: http://external:5100
gateway = "http://localhost:5100"

# The gateway port for the Python backend of poe-api.
# Must be the same as the port indicated in the `gateway` above.
gateway-port = 5100


# Use leading prompts to indicate roles if enabled. You'd better disable it if you are using tools like https://github.com/TheR1D/shell_gpt
# 0:disable, 1:enable, 2:auto detect
# Example:
# ||>User:
# Hello!
# ||Assistant:
# Hello! How can I assist you today?
simulate-roles = 2

# Rate limit. Default to 10 api calls per token in 1 minute
rate-limit = 10

# Cool down of seconds. One same token cannot be used more than once in n seconds
cool-down = 3

# Timeout of seconds per response chunk
# This timeout will now reset every time a chunk is received
# so there's no need for a very large value to compensate for a very long reply
timeout = 15
# Timeout for poe-api, usually it should be smaller than timeout
api-timeout = 12


# The bot name map to use from poe. 
#ã€€
[bot]
        "gpt-3.5-turbo" = "chinchilla" # ChatGPT 3.5
        "gpt-4" = "beaver" # ChatGPT 4
        "gpt-4-turbo-preview" = "vizcacha"
        "gpt-4-vision-preview" = "vizcacha"
        "gpt-3.5-turbo-16k" = "claude_3_haiku_200k"
        "gpt-4-32k" = "claude_2_1_bamboo"
        "gpt-4-32k-0613" = "claude_2_1_cedar"
